{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7c330fd",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465e92f",
   "metadata": {},
   "source": [
    "This is the neural network training and testing pipeline implemented with **pure numpy**.\n",
    "\n",
    "The details of the task and the common things of the neural network architecture are provided in the TorchNN notebooks. The essential of this notebook is the pure-numpy implementation without using any DL frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e6c2d",
   "metadata": {},
   "source": [
    "## Result metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd031c80",
   "metadata": {},
   "source": [
    "As learning on CPU is quite a slow process so here is provided only the test launch. The result (and the only goal) is showing that the algorithm does work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d71c1d",
   "metadata": {},
   "source": [
    "# Imports and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7882ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "from numba import njit\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import display as disp\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3947a7",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20c0f70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class image_objects():\n",
    "    \"\"\"\n",
    "    Image loading and preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, filenames,):\n",
    "        \"\"\"\n",
    "        Initialization.\n",
    "        Loads the metadata from a local disk.\n",
    "        path : files directory\n",
    "        filenames : array of the arrays of the two items (jpg and txt) for each image\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.filenames = filenames\n",
    "        self.augmentation_is_done = False\n",
    "        \n",
    "        self.meta_raw = []\n",
    "        for i in np.arange(self.filenames.shape[0]):\n",
    "            with open(f'{self.path}{self.filenames[i, 1]}', 'r') as f:\n",
    "                string = f.read()\n",
    "            self.meta_raw.append(np.array(string.split(' '), dtype='int'))\n",
    "        \n",
    "        self.meta_raw = np.array(self.meta_raw)\n",
    "    \n",
    "    \n",
    "    def split_indices(self, valid_frac, test_frac,):\n",
    "        \"\"\"\n",
    "        Splits the indices to the train, validation and test samples.\n",
    "        \"\"\"\n",
    "        index = np.arange(self.meta_raw.shape[0])\n",
    "        labels = self.meta_raw[:, 0].copy()\n",
    "        classes = np.unique(self.meta_raw[:, 0])\n",
    "\n",
    "        index_by_class = []\n",
    "\n",
    "        for i in np.arange(classes.shape[0]):\n",
    "            index_by_class.append(index[labels == classes[i]])\n",
    "            np.random.shuffle(index_by_class[i])\n",
    "\n",
    "            bounds = np.array(\n",
    "                [\n",
    "                    index_by_class[i].shape[0] * (1 - (valid_frac + test_frac)),\n",
    "                    index_by_class[i].shape[0] * (1 - test_frac),\n",
    "                ],\n",
    "                dtype = 'int'\n",
    "            )\n",
    "\n",
    "            index_by_class[i] = [\n",
    "                index_by_class[i][:bounds[0]],\n",
    "                index_by_class[i][bounds[0]:bounds[1]],\n",
    "                index_by_class[i][bounds[1]:],\n",
    "            ]\n",
    "\n",
    "        self.index_tr_basic = np.array([], dtype='int')\n",
    "        self.index_va = np.array([], dtype='int')\n",
    "        self.index_te = np.array([], dtype='int')\n",
    "\n",
    "        for i in np.arange(classes.shape[0]):\n",
    "            self.index_tr_basic = np.append(self.index_tr_basic, index_by_class[i][0])\n",
    "            self.index_va = np.append(self.index_va, index_by_class[i][1])\n",
    "            self.index_te = np.append(self.index_te, index_by_class[i][2])\n",
    "\n",
    "        np.random.shuffle(self.index_tr_basic)\n",
    "        np.random.shuffle(self.index_va)\n",
    "        np.random.shuffle(self.index_te)\n",
    "\n",
    "        print(self.index_tr_basic.shape)\n",
    "        print(self.index_va.shape)\n",
    "        print(self.index_te.shape)\n",
    "\n",
    "\n",
    "    def transform(self, size=256,):\n",
    "        \"\"\"\n",
    "        Transforms the images from raw to input-ready format.\n",
    "        size : size of the final square image\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.meta_bw = self.meta_raw.copy()\n",
    "        self.meta_padded = self.meta_raw.copy()\n",
    "        self.meta_resized = self.meta_padded.copy()\n",
    "        self.pads = np.zeros((self.filenames.shape[0], 4), dtype='int')\n",
    "        self.size_raw = []\n",
    "        self.imgs = []\n",
    "        \n",
    "        for i in np.arange(self.filenames.shape[0]):\n",
    "            img = np.array(Image.open(f'{self.path}{self.filenames[i, 0]}'))\n",
    "            if img.ndim == 2:\n",
    "                img = np.expand_dims(img, 2)\n",
    "            self.size_raw.append(img.shape[:2])\n",
    "        \n",
    "            # Black and white\n",
    "            img = np.mean(img, axis=2, dtype='int')\n",
    "            \n",
    "            # Padding\n",
    "            self.pads[i, 0] = (np.max(img.shape[:2]) - img.shape[0]) // 2                     # top\n",
    "            self.pads[i, 1] = (np.max(img.shape[:2]) - img.shape[0]) // 2 + img.shape[0] % 2  # bottom\n",
    "            self.pads[i, 2] = (np.max(img.shape[:2]) - img.shape[1]) // 2                     # left\n",
    "            self.pads[i, 3] = (np.max(img.shape[:2]) - img.shape[1]) // 2 + img.shape[1] % 2  # right\n",
    "            \n",
    "            img = cv2.copyMakeBorder(img, *self.pads[i], cv2.BORDER_REPLICATE)\n",
    "            self.meta_padded[i, 1] += self.pads[i, 2]\n",
    "            self.meta_padded[i, 2] += self.pads[i, 0]\n",
    "            self.meta_padded[i, 3] += self.pads[i, 3]\n",
    "            self.meta_padded[i, 4] += self.pads[i, 1]\n",
    "            \n",
    "            # Resizing\n",
    "            img = cv2.resize(img.astype('float64'), (self.size, self.size), interpolation=cv2.INTER_CUBIC)\n",
    "            self.meta_resized[i] = self.meta_padded[i]\n",
    "            self.meta_resized[i, 1:5] = np.round(self.meta_resized[i, 1:5] * (self.size / np.max(self.size_raw[i])), 0).astype('int')\n",
    "            \n",
    "            self.imgs.append(np.array(img, dtype='uint8'))\n",
    "        \n",
    "        self.imgs = np.array(self.imgs, dtype='uint8')\n",
    "        self.size_raw = np.array(self.size_raw)\n",
    "        \n",
    "        self.print_imgs_array_details()\n",
    "    \n",
    "    \n",
    "    def show(self, i=None, mode='resized', roi=True,):\n",
    "        \"\"\"\n",
    "        Displays the image.\n",
    "        mode : \"raw\", \"bw\", \"padded\", \"resized\"\n",
    "        roi : bool\n",
    "        \"\"\"\n",
    "        # Choosing the item\n",
    "        i = i if i != None else np.random.randint(0, self.filenames.shape[0])\n",
    "        print(i)\n",
    "\n",
    "        # Loading the raw image if necessary\n",
    "        if mode != 'mask':\n",
    "            img_raw = np.array(Image.open(f'{self.path}{self.filenames[i, 0]}'))\n",
    "        \n",
    "        # Computing the image\n",
    "        if mode == 'raw':\n",
    "            img = img_raw\n",
    "            ax_img = plt.imshow(img)\n",
    "            meta = self.meta_raw[i]\n",
    "        elif mode == 'bw':\n",
    "            img = np.mean(img_raw, axis=2, dtype='int')\n",
    "            ax_img = plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "            meta = self.meta_bw[i]\n",
    "        elif mode == 'padded':\n",
    "            img = cv2.copyMakeBorder(np.mean(img_raw, axis=2, dtype='int'), *self.pads[i], cv2.BORDER_REPLICATE)\n",
    "            ax_img = plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "            meta = self.meta_padded[i]\n",
    "        if mode == 'resized':\n",
    "            img = cv2.resize(\n",
    "                cv2.copyMakeBorder(np.mean(img_raw, axis=2, dtype='int'), *self.pads[i], cv2.BORDER_REPLICATE).astype('float64'), \n",
    "                (self.size, self.size),\n",
    "                interpolation=cv2.INTER_CUBIC\n",
    "            )\n",
    "            ax_img = plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "            try:\n",
    "                meta = self.meta_resized[i]\n",
    "            except:\n",
    "                meta = self.meta_augment[i]\n",
    "        if mode == 'mask':\n",
    "            img = self.imgs[i, 1]\n",
    "            ax_img = plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "            try:\n",
    "                meta = self.meta_resized[i]\n",
    "            except:\n",
    "                meta = self.meta_augment[i]\n",
    "        \n",
    "        # Plotting the image\n",
    "        disp(meta)\n",
    "        ax = []\n",
    "        ax.append(ax_img)\n",
    "        if roi:\n",
    "            ax.append(plt.vlines((meta[1], meta[3],), meta[2], meta[4], colors='red'))\n",
    "            ax.append(plt.hlines((meta[2], meta[4],), meta[1], meta[3], colors='red'))\n",
    "        plt.show(ax)\n",
    "    \n",
    "    \n",
    "    def augmentation(self,):\n",
    "        \"\"\"\n",
    "        Implementation of the augmentation.\n",
    "        \"\"\"\n",
    "        if self.augmentation_is_done is not True:\n",
    "            self.imgs = np.append(self.imgs, np.flip(self.imgs[self.index_tr_basic], axis=2), axis=0)\n",
    "            self.imgs = np.append(self.imgs, np.transpose(self.imgs[self.index_tr_basic], axes=(0, 2, 1)), axis=0)\n",
    "            self.imgs = np.append(self.imgs, np.flip(np.transpose(self.imgs[self.index_tr_basic], axes=(0, 2, 1)), axis=2), axis=0)\n",
    "            self.imgs = np.append(self.imgs, np.flip(self.imgs[self.index_tr_basic], axis=1), axis=0)\n",
    "\n",
    "            meta_1 = self.meta_resized[self.index_tr_basic].copy()\n",
    "            meta_2 = self.meta_resized[self.index_tr_basic].copy()\n",
    "            meta_3 = self.meta_resized[self.index_tr_basic].copy()\n",
    "            meta_4 = self.meta_resized[self.index_tr_basic].copy()\n",
    "\n",
    "            meta_1[:, 1] = self.size - self.meta_resized[self.index_tr_basic][:, 3]\n",
    "            meta_1[:, 3] = self.size - self.meta_resized[self.index_tr_basic][:, 1]\n",
    "\n",
    "            meta_2[:, 1] = meta_1[:, 2]\n",
    "            meta_2[:, 2] = self.size - meta_1[:, 3]\n",
    "            meta_2[:, 3] = meta_1[:, 4]\n",
    "            meta_2[:, 4] = self.size - meta_1[:, 1]\n",
    "\n",
    "            meta_3[:, 1] = self.size - meta_2[:, 3]\n",
    "            meta_3[:, 2] = meta_2[:, 2]\n",
    "            meta_3[:, 3] = self.size - meta_2[:, 1]\n",
    "            meta_3[:, 4] = meta_2[:, 4]\n",
    "\n",
    "            meta_4[:, 2] = self.size - self.meta_resized[self.index_tr_basic][:, 4]\n",
    "            meta_4[:, 4] = self.size - self.meta_resized[self.index_tr_basic][:, 2]\n",
    "\n",
    "            self.meta_augment = self.meta_resized.copy()\n",
    "            self.meta_augment = np.append(self.meta_augment, meta_1, axis=0)\n",
    "            self.meta_augment = np.append(self.meta_augment, meta_2, axis=0)\n",
    "            self.meta_augment = np.append(self.meta_augment, meta_3, axis=0)\n",
    "            self.meta_augment = np.append(self.meta_augment, meta_4, axis=0)\n",
    "        \n",
    "        self.index_tr = self.index_tr_basic.copy()\n",
    "        self.index_tr = np.append(self.index_tr, np.arange(self.filenames.shape[0], self.imgs.shape[0]))\n",
    "        \n",
    "        self.meta_ready = self.meta_augment.copy().astype('float64')\n",
    "        self.meta_ready[:, 0][self.meta_ready[:, 0] == 2] = 0\n",
    "        self.meta_ready[:, 1:] = self.meta_ready[:, 1:] * 1. / self.size\n",
    "        \n",
    "        self.augmentation_is_done = True\n",
    "        self.print_imgs_array_details()\n",
    "        \n",
    "\n",
    "    def print_imgs_array_details(self,):\n",
    "        \"\"\"\n",
    "        Displays imgs array shape, memory usage and dtype.\n",
    "        \"\"\"\n",
    "        print(self.imgs.shape)\n",
    "        print(images.imgs.nbytes // 1024**2, 'Mb')\n",
    "        print(self.imgs.dtype)\n",
    "    \n",
    "    \n",
    "    def unsqueeze_imgs(self,):\n",
    "        \"\"\"\n",
    "        Inserts additional dimention in the second position (dim 1).\n",
    "        \n",
    "        For example:\n",
    "        Shape: (1000, 192, 192) ---> (1000, 1, 192, 192)\n",
    "        \"\"\"\n",
    "        self.imgs = self.imgs.reshape(self.imgs.shape[0], 1, self.imgs.shape[1], self.imgs.shape[2])\n",
    "        self.print_imgs_array_details()\n",
    "    \n",
    "    \n",
    "    def create_roi_masks(self,):\n",
    "        \"\"\"\n",
    "        Creates the binary layer where pixels of ROI are ones and others are zeros.\n",
    "        USING THIS FOR TRAINING IS A LEAK!!!\n",
    "        \"\"\"\n",
    "        self.imgs = self.imgs.reshape(self.imgs.shape[0], 1, self.imgs.shape[1], self.imgs.shape[2])\n",
    "        self.imgs = np.concatenate((self.imgs, np.full(self.imgs.shape, 255, dtype='uint8')), axis=1)\n",
    "        \n",
    "        for i in np.arange(self.imgs.shape[0]):\n",
    "            self.imgs[\n",
    "                i,\n",
    "                1,\n",
    "                self.meta_augment[i, 2] : self.meta_augment[i, 4],\n",
    "                self.meta_augment[i, 1] : self.meta_augment[i, 3],\n",
    "            ] = 0\n",
    "        \n",
    "        self.print_imgs_array_details()\n",
    "    \n",
    "    \n",
    "    def augmentation_show(self, i=None, mask=False,):\n",
    "        \"\"\"\n",
    "        Displays the set of images after augmentation.\n",
    "        \"\"\"\n",
    "        i = i if i != None else np.random.randint(0, self.index_tr_basic.shape[0])\n",
    "        print(i)\n",
    "        print(self.index_tr_basic[i])\n",
    "        \n",
    "        AUGS = 5\n",
    "        fig, ax = plt.subplots(1, AUGS, figsize=(20, 5))\n",
    "        \n",
    "        for aug in np.arange(AUGS):\n",
    "            if aug == 0:\n",
    "                j = self.index_tr_basic[i]\n",
    "            else:\n",
    "                j = self.filenames.shape[0] + i + (aug - 1) * self.index_tr_basic.shape[0]\n",
    "            disp(self.meta_augment[j])\n",
    "            if self.imgs.ndim == 3:\n",
    "                ax[aug].imshow(self.imgs[j], cmap='gray',)\n",
    "            elif self.imgs.ndim == 4:\n",
    "                layer = 1 if mask else 0\n",
    "                ax[aug].imshow(self.imgs[j, layer], cmap='gray',)\n",
    "            ax[aug].vlines((self.meta_augment[j, 1], self.meta_augment[j, 3],), self.meta_augment[j, 2], self.meta_augment[j, 4], colors='red')\n",
    "            ax[aug].hlines((self.meta_augment[j, 2], self.meta_augment[j, 4],), self.meta_augment[j, 1], self.meta_augment[j, 3], colors='red')\n",
    "\n",
    "        plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb5be21",
   "metadata": {},
   "source": [
    "## Loading with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af69f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/images256.pkl', 'rb') as f:\n",
    "    images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3a145",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba001f4",
   "metadata": {},
   "source": [
    "## Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c2904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def numpy_padding(\n",
    "    arr_input,\n",
    "    padding,\n",
    "):\n",
    "    \"\"\"\n",
    "    Padding operation implemented with numpy.\n",
    "    arr_input = (N, C, H, W)\n",
    "    \"\"\"\n",
    "    # Init\n",
    "    assert(arr_input.ndim == 4)\n",
    "    arr = arr_input.copy()\n",
    "    dtype = arr.dtype\n",
    "    \n",
    "    # Padding\n",
    "    arr_padded = np.zeros(\n",
    "        (\n",
    "            arr.shape[0],\n",
    "            arr.shape[1],\n",
    "            arr.shape[2] + (2 * padding),\n",
    "            arr.shape[3] + (2 * padding),\n",
    "        ),\n",
    "        dtype = dtype,\n",
    "    )\n",
    "    for i, item in enumerate(arr):\n",
    "        for c, channel in enumerate(item):\n",
    "            padded = np.append(np.zeros((padding, channel.shape[1])), channel, axis=0)\n",
    "            padded = np.append(padded, np.zeros((padding, padded.shape[1])), axis=0)\n",
    "            padded = np.append(np.zeros((padded.shape[0], padding)), padded, axis=1)\n",
    "            padded = np.append(padded, np.zeros((padded.shape[0], padding)), axis=1)\n",
    "            arr_padded[i, c] = padded\n",
    "    \n",
    "    return arr_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8837a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class numpy_Conv2d():\n",
    "    \"\"\"\n",
    "    Convolutional layer for 2D arrays implemented with numpy.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        batch_size,\n",
    "        padding = 1,\n",
    "        stride = 1,\n",
    "        debug_step = 0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Init function.\n",
    "        \"\"\"\n",
    "        # Misc init\n",
    "        self.out_channels = out_channels\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.debug_step = debug_step\n",
    "        \n",
    "        # Kernel init\n",
    "        self.kernel = np.random.rand(out_channels, in_channels, kernel_size, kernel_size) * 1e-2\n",
    "    \n",
    "    \n",
    "    def compute(\n",
    "        self,\n",
    "        arr_input,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Convolutional layer core function.\n",
    "        arr_input = (N, C, H, W)\n",
    "        \"\"\"\n",
    "        # Init\n",
    "        assert(arr_input.ndim == 4)\n",
    "        arr = arr_input.copy()\n",
    "        dtype = arr.dtype\n",
    "\n",
    "        # Padding\n",
    "        if self.padding > 0:\n",
    "            arr = numpy_padding(arr, self.padding)\n",
    "        \n",
    "        # Computing\n",
    "        return mul_conv(arr, self.kernel, self.stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22fe79b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def mul_conv(arr, kernel, stride,):\n",
    "    \"\"\"\n",
    "    Implementation of the multiplication.\n",
    "    Accelerated function for the \"numpy_Conv2d\" class.\n",
    "    \"\"\"\n",
    "    arr_conv = np.empty(\n",
    "        (\n",
    "            arr.shape[0],\n",
    "            kernel.shape[0],\n",
    "            (arr.shape[2] - kernel.shape[2] + stride) // stride,\n",
    "            (arr.shape[3] - kernel.shape[3] + stride) // stride,\n",
    "        ),\n",
    "        dtype = arr.dtype,\n",
    "    )\n",
    "\n",
    "    for c_out in np.arange(arr_conv.shape[1]):\n",
    "        for i in np.arange(arr_conv.shape[0]):\n",
    "            for h in np.arange(arr_conv.shape[2]):\n",
    "                for w in np.arange(arr_conv.shape[3]):\n",
    "                    arr_conv[i, c_out, h, w] = np.sum(\n",
    "                        kernel[c_out] * arr[\n",
    "                            i,\n",
    "                            :arr.shape[1],\n",
    "                            h * stride : h * stride + kernel.shape[2],\n",
    "                            w * stride : w * stride + kernel.shape[3],\n",
    "                        ]\n",
    "                    )\n",
    "    \n",
    "    return arr_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aad5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def numpy_ReLU(\n",
    "    arr_input,\n",
    "):\n",
    "    \"\"\"\n",
    "    Rectified linear unit layer implemented with numpy.\n",
    "    arr_input = (N, C, H, W)\n",
    "    \"\"\"\n",
    "    return np.where(arr_input > 0., arr_input, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654f3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "class numpy_Pool2d():\n",
    "    \"\"\"\n",
    "    Pooling layer for 2D arrays implemented with numpy.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        func,  # \"max\", \"mean\"\n",
    "        kernel_size,\n",
    "        padding = 0,\n",
    "        stride = 2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Init function.\n",
    "        \"\"\"\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.func = func\n",
    "    \n",
    "\n",
    "    def compute(\n",
    "        self,\n",
    "        arr_input,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Pooling layer core function.\n",
    "\n",
    "        arr_input = (N, C, H, W)\n",
    "        \"\"\"\n",
    "        # Init\n",
    "        assert(arr_input.ndim == 4)\n",
    "        arr = arr_input.copy()\n",
    "\n",
    "        # Padding\n",
    "        if self.padding > 0:\n",
    "            arr = numpy_padding(arr, self.padding)\n",
    "\n",
    "        # Computing\n",
    "        if self.func == 'max':\n",
    "            return mul_maxpool(arr, self.kernel_size, self.stride)  # arr_pool, arr_pool_argmax\n",
    "        elif self.func == 'mean':\n",
    "            return mul_avgpool(arr, self.kernel_size, self.stride)  # arr_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3bb07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def mul_maxpool(\n",
    "    arr,\n",
    "    kernel_size,\n",
    "    stride,\n",
    "):\n",
    "    \"\"\"\n",
    "    Implementation of the multiplication.\n",
    "    Accelerated function for the \"numpy_Conv2d\" class.\n",
    "    \"\"\"\n",
    "    # Pool array init\n",
    "    arr_pool = np.empty(\n",
    "        (\n",
    "            arr.shape[0],\n",
    "            arr.shape[1],\n",
    "            (arr.shape[2] - kernel_size + stride) // stride,\n",
    "            (arr.shape[3] - kernel_size + stride) // stride,\n",
    "        ),\n",
    "        dtype = arr.dtype\n",
    "    )\n",
    "\n",
    "    # Argmax array init\n",
    "    arr_pool_argmax = np.empty(\n",
    "        (\n",
    "            arr.shape[0],\n",
    "            arr.shape[1],\n",
    "            (arr.shape[2] - kernel_size + stride) // stride,\n",
    "            (arr.shape[3] - kernel_size + stride) // stride,\n",
    "            np.int(2),\n",
    "        ),\n",
    "        dtype = arr.dtype\n",
    "    )\n",
    "\n",
    "    # Computing\n",
    "    for i in np.arange(arr_pool.shape[0]):\n",
    "        for c in np.arange(arr_pool.shape[1]):\n",
    "            for h in np.arange(arr_pool.shape[2]):\n",
    "                for w in np.arange(arr_pool.shape[3]):\n",
    "                    piece_of_arr = arr[i, c, h * stride : h * stride + kernel_size, w * stride : w * stride + kernel_size,]\n",
    "                    arr_pool[i, c, h, w] = np.amax(piece_of_arr)\n",
    "                    agrmax_thorough = np.argmax(piece_of_arr)\n",
    "                    arr_pool_argmax[i, c, h, w, 0] = agrmax_thorough // piece_of_arr.shape[1]\n",
    "                    arr_pool_argmax[i, c, h, w, 1] = agrmax_thorough - (agrmax_thorough // piece_of_arr.shape[1]) * piece_of_arr.shape[1]\n",
    "\n",
    "    return arr_pool, arr_pool_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3039961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def mul_avgpool(\n",
    "    arr,\n",
    "    kernel_size,\n",
    "    stride,\n",
    "):\n",
    "    \"\"\"\n",
    "    Implementation of the multiplication.\n",
    "    Accelerated function for the \"numpy_Conv2d\" class.\n",
    "    \"\"\"\n",
    "    # Pool array init\n",
    "    arr_pool = np.empty(\n",
    "        (\n",
    "            arr.shape[0],\n",
    "            arr.shape[1],\n",
    "            (arr.shape[2] - kernel_size + stride) // stride,\n",
    "            (arr.shape[3] - kernel_size + stride) // stride,\n",
    "        ),\n",
    "        dtype = arr.dtype\n",
    "    )\n",
    "\n",
    "    # Computing\n",
    "    for i in np.arange(arr_pool.shape[0]):\n",
    "        for c in np.arange(arr_pool.shape[1]):\n",
    "            for h in np.arange(arr_pool.shape[2]):\n",
    "                for w in np.arange(arr_pool.shape[3]):\n",
    "                    arr_pool[i, c, h, w] = np.mean(\n",
    "                        arr[i, c, h * stride : h * stride + kernel_size, w * stride : w * stride + kernel_size,],\n",
    "                    )\n",
    "\n",
    "    return arr_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31048b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_Sigmoid(\n",
    "    arr_input,\n",
    "):\n",
    "    \"\"\"\n",
    "    Sigmoid layer implemented with numpy.\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "    exp_safe_bound = -700.\n",
    "    \n",
    "    arr_input[arr_input < exp_safe_bound] = exp_safe_bound\n",
    "    \n",
    "    return 1 / (1 + np.exp(-arr_input)) + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45297658",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def numpy_Dropout(\n",
    "    arr_input,\n",
    "    p,\n",
    "):\n",
    "    \"\"\"\n",
    "    Dropout layer implemented with numpy.\n",
    "    arr_input = (N, C, H, W)\n",
    "    \"\"\"\n",
    "    rand = np.random.rand(*arr_input.shape)\n",
    "    weight_coef = np.where(rand > p, 1., 0.)\n",
    "    \n",
    "    return arr_input * weight_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8682e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class numpy_Linear():\n",
    "    \"\"\"\n",
    "    Linear layer implemented with numpy.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_units,\n",
    "        out_units,\n",
    "        batch_size,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Init function.\n",
    "        \"\"\"\n",
    "        self.out_units = out_units\n",
    "        self.weights = np.random.rand(self.out_units, in_units) * 1e-2\n",
    "        self.biases = np.random.rand(self.out_units) * 1e-2\n",
    "        \n",
    "    \n",
    "    def compute(\n",
    "        self,\n",
    "        arr_input,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Linear layer core function.\n",
    "        arr_input = (N, L)\n",
    "        \"\"\"\n",
    "        # Init\n",
    "        assert(arr_input.ndim == 2)\n",
    "        dtype = arr_input.dtype\n",
    "\n",
    "        # Output array init\n",
    "        arr_output = np.empty(\n",
    "            (\n",
    "                arr_input.shape[0],\n",
    "                self.out_units,\n",
    "            ),\n",
    "            dtype = dtype,\n",
    "        )\n",
    "    \n",
    "        # Computing\n",
    "        return mul_linear(arr_input, arr_output, self.weights, self.biases,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9e564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def mul_linear(arr, arr_output, weights, biases,):\n",
    "    \"\"\"\n",
    "    Implementation of the multiplication.\n",
    "    Accelerated function for the \"numpy_Linear\" class.\n",
    "    \"\"\"\n",
    "    for i in np.arange(arr_output.shape[0]):\n",
    "        for j in np.arange(arr_output.shape[1]):\n",
    "            arr_output[i, j] = np.sum(\n",
    "                arr[i] * weights[j]\n",
    "            ) + biases[j]\n",
    "    \n",
    "    return arr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a85c60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def linear_mul_grad(arr, W, X,):\n",
    "    \"\"\"\n",
    "    Computation of the linear layer multiplication gradient.\n",
    "    \"\"\"\n",
    "    arr_output_a = np.zeros(\n",
    "        (\n",
    "            arr.shape[0],\n",
    "            W.shape[1],\n",
    "        ),\n",
    "        dtype = arr.dtype,\n",
    "    )\n",
    "    \n",
    "    arr_output_b = np.zeros(\n",
    "        (\n",
    "            arr.shape[1],\n",
    "            X.shape[1],\n",
    "        ),\n",
    "        dtype = arr.dtype,\n",
    "    )\n",
    "    \n",
    "    for i in np.arange(arr.shape[0]):\n",
    "        arr_output_a[i] = W.T.dot(arr[i])\n",
    "        arr_output_b += X[i].reshape(-1, 1).dot(arr[i].reshape(-1, 1).T).T\n",
    "    \n",
    "    return arr_output_a, arr_output_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e5d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def avg_pool_grad(arr_input, kernel_size, stride, arr_prev,):\n",
    "    \"\"\"\n",
    "    Computation of the average pooling layer gradient placed before a block\n",
    "    of linear layers.\n",
    "    \"\"\"\n",
    "    arr = arr_input if arr_input.ndim > 2 else arr_input.reshape(*arr_input.shape, 1, 1)\n",
    "    \n",
    "    arr_output = np.zeros(\n",
    "        arr_prev.shape,\n",
    "        dtype = arr_prev.dtype,\n",
    "    )\n",
    "    \n",
    "    for i in np.arange(arr.shape[0]):\n",
    "        for c in np.arange(arr.shape[1]):\n",
    "            for h in np.arange(arr.shape[2]):\n",
    "                for w in np.arange(arr.shape[3]):\n",
    "                    arr_output[\n",
    "                        i,\n",
    "                        c,\n",
    "                        h * stride : h * stride + kernel_size,\n",
    "                        w * stride : w * stride + kernel_size,\n",
    "                    ] += arr[i, c, h, w] / kernel_size ** 2\n",
    "    \n",
    "    return arr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f151ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def max_pool_grad(arr_input, kernel_size, stride, arr_prev, argmax,):\n",
    "    \"\"\"\n",
    "    Computation of the maximum pooling layer gradient placed before a block\n",
    "    of linear layers.\n",
    "    \"\"\"\n",
    "    arr = arr_input if arr_input.ndim > 2 else arr_input.reshape(*arr_input.shape, 1, 1)\n",
    "    \n",
    "    arr_output = np.zeros(\n",
    "        arr_prev.shape,\n",
    "        dtype = arr_prev.dtype,\n",
    "    )\n",
    "    \n",
    "    for i in np.arange(arr.shape[0]):\n",
    "        for c in np.arange(arr.shape[1]):\n",
    "            for h in np.arange(arr.shape[2]):\n",
    "                for w in np.arange(arr.shape[3]):\n",
    "                    arr_output[\n",
    "                        i,\n",
    "                        c,\n",
    "                        h * stride + int(argmax[i, c, h, w, 0]),\n",
    "                        w * stride + int(argmax[i, c, h, w, 1]),\n",
    "                    ] = arr[i, c, h, w]\n",
    "    \n",
    "    return arr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5761741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def conv_mul_grad(X, grad_input, kernel, padding, stride,):\n",
    "    \"\"\"\n",
    "    Computation of the convolutional layer multiplication gradient.\n",
    "    \"\"\"\n",
    "    # dX\n",
    "    arr_output_a = np.zeros(\n",
    "        (\n",
    "            X.shape[0],\n",
    "            X.shape[1],\n",
    "            X.shape[2] + 2 * padding,\n",
    "            X.shape[3] + 2 * padding,\n",
    "        ),\n",
    "        dtype = X.dtype,\n",
    "    )\n",
    "\n",
    "    for i in np.arange(grad_input.shape[0]):\n",
    "        for c_out in np.arange(grad_input.shape[1]):\n",
    "            for h in np.arange(grad_input.shape[2]):\n",
    "                for w in np.arange(grad_input.shape[3]):\n",
    "                    arr_output_a[\n",
    "                        i,\n",
    "                        :,\n",
    "                        h * stride : h * stride + kernel.shape[2],\n",
    "                        w * stride : w * stride + kernel.shape[3],\n",
    "                    ] += kernel[c_out] * grad_input[i, c_out, h, w]\n",
    "\n",
    "    arr_output_a = arr_output_a[:, :, 1:-1, 1:-1]\n",
    "    \n",
    "    # dW\n",
    "    arr_output_b = np.zeros(\n",
    "        kernel.shape,\n",
    "        dtype = kernel.dtype,\n",
    "    )\n",
    "    \n",
    "    for i in np.arange(grad_input.shape[0]):\n",
    "        for c_out in np.arange(grad_input.shape[1]):\n",
    "            for h_k in np.arange(arr_output_b.shape[2]):\n",
    "                for w_k in np.arange(arr_output_b.shape[3]):\n",
    "                    for h in np.arange(h_k, X.shape[2], stride):\n",
    "                        for w in np.arange(w_k, X.shape[3], stride):\n",
    "                            arr_output_b[c_out, :, h_k, w_k] += X[i, :, h, w]\n",
    "    \n",
    "    return arr_output_a, arr_output_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04272209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class numpy_Adam():\n",
    "    \"\"\"\n",
    "    Adam optimizer implemented with numpy.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        learnable_entities_names,\n",
    "        beta1 = 0.9,\n",
    "        beta2 = 0.999,\n",
    "        eps = 1e-8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Init function.\n",
    "        \"\"\"\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.step_params = {}\n",
    "        for name in learnable_entities_names:\n",
    "            self.step_params[name] = {\n",
    "                'm': 0,\n",
    "                'v': 0,\n",
    "            }\n",
    "        \n",
    "        self.t = 1\n",
    "        \n",
    "        \n",
    "    def step(\n",
    "        self,\n",
    "        dw,\n",
    "        name,\n",
    "        learning_rate = 0.01,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Step function.\n",
    "        \"\"\"\n",
    "        self.step_params[name]['m'] = self.beta1 * self.step_params[name]['m'] + (1 - self.beta1) * dw\n",
    "        mt = self.step_params[name]['m'] / (1 - self.beta1 ** self.t)\n",
    "        self.step_params[name]['v'] = self.beta2 * self.step_params[name]['v'] + (1 - self.beta2) * (dw ** 2)\n",
    "        vt = self.step_params[name]['v'] / (1 - self.beta2 ** self.t)\n",
    "        \n",
    "        dw_output = -1. * learning_rate * mt / (np.sqrt(vt) + self.eps)\n",
    "        self.t += 1\n",
    "        \n",
    "        return dw_output\n",
    "    \n",
    "    \n",
    "    def state_dict(self,):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8ad2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class numpy_Net():\n",
    "    \"\"\"\n",
    "    Neural network implemented with numpy.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        batch_size,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialization function.\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.conv00 = numpy_Conv2d(1, 12, 3, self.batch_size, padding=1, stride=1, debug_step=0,)\n",
    "        self.pool00 = numpy_Pool2d('max', 4, padding=0, stride=4)\n",
    "        self.conv01 = numpy_Conv2d(12, 10, 3, self.batch_size, padding=1, stride=1, debug_step=1,)\n",
    "        self.pool01 = numpy_Pool2d('max', 4, padding=0, stride=4)\n",
    "        self.conv02 = numpy_Conv2d(10, 12, 3, self.batch_size, padding=1, stride=2)\n",
    "        self.pool02 = numpy_Pool2d('max', 2, padding=0, stride=2)\n",
    "        self.conv03 = numpy_Conv2d(12, 12, 3, self.batch_size, padding=1, stride=2)\n",
    "        self.pool03 = numpy_Pool2d('mean', 2, padding=0, stride=2)\n",
    "        self.linear00 = numpy_Linear(12, 10, self.batch_size)\n",
    "        self.linear01 = numpy_Linear(10, 5, self.batch_size)\n",
    "        \n",
    "        self.optimizer = numpy_Adam(\n",
    "            ('conv00_weights', 'conv01_weights', 'conv02_weights', 'conv03_weights', 'linear00_weights', 'linear00_biases', 'linear01_weights', 'linear01_biases',),\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x_input,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Forward pass function.\n",
    "        \"\"\"\n",
    "        self.x_input = x_input\n",
    "        \n",
    "        self.x00 = self.conv00.compute(self.x_input)\n",
    "        self.x01 = numpy_ReLU(self.x00)\n",
    "        self.x02, self.x02_argmax = self.pool00.compute(self.x01)\n",
    "        self.x03 = self.conv01.compute(self.x02)\n",
    "        self.x04 = numpy_ReLU(self.x03)\n",
    "        self.x05, self.x05_argmax = self.pool01.compute(self.x04)\n",
    "        self.x06 = self.conv02.compute(self.x05)\n",
    "        self.x07 = numpy_ReLU(self.x06)\n",
    "        self.x08, self.x08_argmax = self.pool02.compute(self.x07)\n",
    "        self.x09 = self.conv03.compute(self.x08)\n",
    "        self.x10 = numpy_Sigmoid(self.x09)\n",
    "        self.x11 = self.pool03.compute(self.x10)\n",
    "        self.x12 = numpy_Dropout(self.x11, p=0.5)\n",
    "\n",
    "        self.x13 = np.squeeze(self.x12)\n",
    "        self.x14 = self.linear00.compute(self.x13)\n",
    "        self.x15 = numpy_Sigmoid(self.x14)\n",
    "        self.x16 = self.linear01.compute(self.x15)\n",
    "        self.x_output = numpy_Sigmoid(self.x16)\n",
    "\n",
    "        return self.x_output\n",
    "    \n",
    "    \n",
    "    def backward(\n",
    "        self,\n",
    "        y,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Backward pass function.\n",
    "        \"\"\"\n",
    "        # loss function gradient\n",
    "        dx = y - self.x_output\n",
    "#         dx = (y - self.x_output) / (self.x_output - self.x_output_prev)\n",
    "        \n",
    "        # sigmoid gradient\n",
    "        df1 = (1 - numpy_Sigmoid(dx)) * numpy_Sigmoid(dx)\n",
    "\n",
    "        # adding gradient\n",
    "        df2a = df1\n",
    "        self.df2b = np.sum(df1, axis=0)\n",
    "            \n",
    "        # linear multiplication gradient\n",
    "        df3a, self.df3b = linear_mul_grad(df2a, self.linear01.weights, self.x15,)\n",
    "\n",
    "        # sigmoid gradient\n",
    "        df4 = (1 - numpy_Sigmoid(df3a)) * numpy_Sigmoid(df3a)\n",
    "            \n",
    "        # adding gradient\n",
    "        df5a = df4\n",
    "        self.df5b = np.sum(df4, axis=0)\n",
    "\n",
    "        # linear multiplication gradient\n",
    "        df6a, self.df6b = linear_mul_grad(df5a, self.linear00.weights, self.x13,)\n",
    "            \n",
    "        # average pooling gradient\n",
    "        df7 = avg_pool_grad(df6a, self.pool03.kernel_size, self.pool03.stride, self.x10,)\n",
    "\n",
    "        # sigmoid gradient\n",
    "        df8 = (1 - numpy_Sigmoid(df7)) * numpy_Sigmoid(df7)\n",
    "            \n",
    "        # convolutional multiplication gradient\n",
    "        df9a, self.df9b = conv_mul_grad(self.x08, df8, self.conv03.kernel, self.conv03.padding, self.conv03.stride)\n",
    "            \n",
    "        # maximum pooling gradient\n",
    "        df10 = max_pool_grad(df9a, self.pool02.kernel_size, self.pool02.stride, self.x07, self.x08_argmax)\n",
    "\n",
    "        # convolutional multiplication gradient\n",
    "        df11a, self.df11b = conv_mul_grad(self.x05, df10, self.conv02.kernel, self.conv02.padding, self.conv02.stride)\n",
    "\n",
    "        # maximum pooling gradient\n",
    "        df12 = max_pool_grad(df11a, self.pool01.kernel_size, self.pool01.stride, self.x04, self.x05_argmax)\n",
    "\n",
    "        # convolutional multiplication gradient\n",
    "        df13a, self.df13b = conv_mul_grad(self.x02, df12, self.conv01.kernel, self.conv01.padding, self.conv01.stride)\n",
    "\n",
    "        # maximum pooling gradient\n",
    "        df14 = max_pool_grad(df13a, self.pool00.kernel_size, self.pool00.stride, self.x01, self.x02_argmax)\n",
    "\n",
    "        # convolutional multiplication gradient\n",
    "        df15a, self.df15b = conv_mul_grad(self.x_input, df14, self.conv00.kernel, self.conv00.padding, self.conv00.stride)\n",
    "        \n",
    "\n",
    "    def optimizer_step(\n",
    "        self,\n",
    "        learning_rate,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Optimizer step function.\n",
    "        \"\"\"\n",
    "        self.linear01.biases += self.optimizer.step(self.df2b, 'linear01_biases', learning_rate=learning_rate,)\n",
    "        self.linear01.weights += self.optimizer.step(self.df3b, 'linear01_weights', learning_rate=learning_rate,)\n",
    "        self.linear00.biases += self.optimizer.step(self.df5b, 'linear00_biases', learning_rate=learning_rate,)\n",
    "        self.linear00.weights += self.optimizer.step(self.df6b, 'linear00_weights', learning_rate=learning_rate,)\n",
    "        self.conv03.kernel += self.optimizer.step(self.df9b, 'conv03_weights', learning_rate=learning_rate,)\n",
    "        self.conv02.kernel += self.optimizer.step(self.df11b, 'conv02_weights', learning_rate=learning_rate,)\n",
    "        self.conv01.kernel += self.optimizer.step(self.df13b, 'conv01_weights', learning_rate=learning_rate,)\n",
    "        self.conv00.kernel += self.optimizer.step(self.df15b, 'conv00_weights', learning_rate=learning_rate,)\n",
    "    \n",
    "    \n",
    "    def state_dict(self,):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751e568",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0048d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class numpy_Trainer():\n",
    "    \"\"\"\n",
    "    Implementation of the neural network training process with numpy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "    \n",
    "    \n",
    "    def epoch_func(self, epoch, mode, X, y,):\n",
    "        '''\n",
    "        Implementation of the training and the validation during one epoch.\n",
    "        '''\n",
    "        # Time of the beginning\n",
    "        time_begin = datetime.datetime.now()\n",
    "        \n",
    "        # Initializing global vars\n",
    "        y_pred = np.empty(\n",
    "            (\n",
    "                0,\n",
    "                y.shape[1],\n",
    "            ),\n",
    "            dtype = y.dtype,\n",
    "        )\n",
    "        epoch_loss = 0\n",
    "        epoch_loss_mciou = 0\n",
    "        epoch_loss_bce = 0\n",
    "        batches = 0\n",
    "        PIXEL_VALUES_RANGE = 255\n",
    "        \n",
    "        # Batch loop\n",
    "        for i in np.arange(0, X.shape[0], self.batch_size):\n",
    "            X_batch = X[i : i + self.batch_size] * 1. / PIXEL_VALUES_RANGE\n",
    "            y_batch = y[i : i + self.batch_size]\n",
    "            \n",
    "            # Computing\n",
    "            y_pred_batch = self.model.forward(X_batch)\n",
    "            batch_loss, batch_loss_bce, batch_loss_mciou = self.criterion.forward(y_pred_batch, y_batch)\n",
    "            \n",
    "            if mode == 'train':\n",
    "                self.model.backward(y_batch)\n",
    "                self.model.optimizer_step(self.learning_rate)                \n",
    "\n",
    "            # Collecting batch results\n",
    "            epoch_loss += batch_loss\n",
    "            epoch_loss_bce += batch_loss_bce\n",
    "            epoch_loss_mciou += batch_loss_mciou\n",
    "            batches += 1\n",
    "            y_pred = np.concatenate((y_pred, y_pred_batch))\n",
    "        \n",
    "        # Loss and metrics\n",
    "        epoch_loss /= batches\n",
    "        epoch_loss_bce /= batches\n",
    "        epoch_loss_mciou /= batches\n",
    "        \n",
    "        accuracy = numpy_accuracy_score(\n",
    "            y[:, 0],\n",
    "            y_pred[:, 0],\n",
    "        )\n",
    "        \n",
    "        iou_metric = numpy_iou(y_pred[:, 1:], y[:, 1:])\n",
    "        miou = iou_metric.mean_iou_score()\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.epoch_loss_tr = epoch_loss\n",
    "            self.epoch_loss_bce_tr = epoch_loss_bce\n",
    "            self.epoch_loss_mciou_tr = epoch_loss_mciou\n",
    "            self.accuracy_tr = accuracy\n",
    "            self.miou_tr = miou\n",
    "            self.walltime_tr = (datetime.datetime.now() - time_begin).total_seconds()\n",
    "        elif mode == 'valid':\n",
    "            self.epoch_loss_va = epoch_loss\n",
    "            self.epoch_loss_bce_va = epoch_loss_bce\n",
    "            self.epoch_loss_mciou_va = epoch_loss_mciou\n",
    "            self.accuracy_va = accuracy\n",
    "            self.miou_va = miou\n",
    "            self.walltime_va = (datetime.datetime.now() - time_begin).total_seconds()\n",
    "        elif mode == 'test':\n",
    "            epoch_loss_te = epoch_loss\n",
    "            accuracy_te = accuracy\n",
    "            miou_te = miou\n",
    "            walltime_te = (datetime.datetime.now() - time_begin) / datetime.timedelta(microseconds=1)\n",
    "        \n",
    "        # Saving state dicts\n",
    "        if mode == 'valid':\n",
    "            self.state_dicts.append(\n",
    "                [\n",
    "                    {}, #deepcopy(self.model.state_dict()),\n",
    "                    {}, #deepcopy(self.optimizer.state_dict()),\n",
    "                    {\n",
    "                        'epoch': epoch,\n",
    "                        'loss_tr': self.epoch_loss_tr,\n",
    "                        'loss_va': self.epoch_loss_va,\n",
    "                        'acc_tr': self.accuracy_tr,\n",
    "                        'acc_va': self.accuracy_va,\n",
    "                        'loss_bce_tr': self.epoch_loss_bce_tr,\n",
    "                        'loss_bce_va': self.epoch_loss_bce_va,\n",
    "                        'loss_mciou_tr': self.epoch_loss_mciou_tr,\n",
    "                        'loss_mciou_va': self.epoch_loss_mciou_va,\n",
    "                        'miou_tr': self.miou_tr,\n",
    "                        'miou_va': self.miou_va,\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        # Verbosing\n",
    "        if mode == 'valid':\n",
    "            walltime = self.walltime_tr + self.walltime_va\n",
    "            verbose_string = ('[{:03d}] wall: {:3d}:{:02d},  loss: {:.3f} / {:.3f},  acc.: {:.3f} / {:.3f},  bce_loss: {:.3f} / {:.3f},  mciou_loss: {:.3f} / {:.3f},  miou: {:.3f} / {:.3f}  [{:03d}]'\n",
    "                  .format(\n",
    "                      epoch,\n",
    "                      int(walltime // 60),\n",
    "                      int(walltime % 60),\n",
    "                      self.epoch_loss_tr,\n",
    "                      self.epoch_loss_va,\n",
    "                      self.accuracy_tr,\n",
    "                      self.accuracy_va,\n",
    "                      self.epoch_loss_bce_tr,\n",
    "                      self.epoch_loss_bce_va,\n",
    "                      self.epoch_loss_mciou_tr,\n",
    "                      self.epoch_loss_mciou_va,\n",
    "                      self.miou_tr,\n",
    "                      self.miou_va,\n",
    "                      epoch,\n",
    "                  )\n",
    "                 )\n",
    "            self.verbose_strings.append(verbose_string)\n",
    "            if epoch % self.graph_refreshing_interval == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f'The training graph is refreshed every {self.graph_refreshing_interval} epochs.')\n",
    "                self.training_graph()\n",
    "                for i in np.arange(len(self.verbose_strings)):\n",
    "                    print(self.verbose_strings[i])\n",
    "            else:\n",
    "                print(verbose_string)\n",
    "        elif mode == 'test':\n",
    "            walltime = np.round((walltime_te / 1e6), 3)  # seconds\n",
    "            inference_time = np.round(((walltime_te / y.shape[0]) / 1e3), 3)  # milliseconds\n",
    "            print('[test] wall: {:.3f}s,  inference: {:.3f}ms,  loss: {:.3f},  acc.: {:.3f},  miou: {:.3f}  [test]'\n",
    "                  .format(\n",
    "                      walltime,\n",
    "                      inference_time,\n",
    "                      epoch_loss_te,\n",
    "                      accuracy_te,\n",
    "                      miou_te,\n",
    "                  )\n",
    "                 )\n",
    "        \n",
    "\n",
    "    def training_graph(self,):\n",
    "        \"\"\"\n",
    "        Plots the training graph.\n",
    "        \"\"\"\n",
    "        # Data array init\n",
    "        training_results = np.empty((len(self.state_dicts), len(self.state_dicts[0][2])), dtype='float64')\n",
    "        \n",
    "        # Collecting the data\n",
    "        for i in np.arange(len(self.state_dicts)):\n",
    "            for j, key in enumerate(self.state_dicts[i][2].keys()):\n",
    "                training_results[i, j] = self.state_dicts[i][2][key]\n",
    "        legend = []\n",
    "        for key in self.state_dicts[0][2].keys():\n",
    "            legend.append(key)\n",
    "        \n",
    "        # Plotting\n",
    "        right_plot_bound = 10  # 100\n",
    "        plt.figure(figsize=(20, 8))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(training_results[:, 0], training_results[:, 5:9])\n",
    "        plt.plot(training_results[:, 0], training_results[:, 1:3])\n",
    "        plt.legend((*legend[5:9], *legend[1:3],))\n",
    "        plt.xlim((0, (training_results[-1, 0] // right_plot_bound + 1) * right_plot_bound))\n",
    "        plt.subplot(122)\n",
    "        plt.plot(training_results[:, 0], training_results[:, 3:5])\n",
    "        plt.plot(training_results[:, 0], training_results[:, 9:11])\n",
    "        plt.legend((*legend[3:5], *legend[9:11],))\n",
    "        plt.xlim((0, (training_results[-1, 0] // right_plot_bound + 1) * right_plot_bound))\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        X_tr,\n",
    "        X_va,\n",
    "        y_tr,\n",
    "        y_va,\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        epochs = 10,\n",
    "        graph_refreshing_interval = 1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of the model training.\n",
    "        \"\"\"\n",
    "        # Vars init\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Output vars init\n",
    "        self.state_dicts = []\n",
    "        self.verbose_strings = []\n",
    "        self.graph_refreshing_interval = graph_refreshing_interval\n",
    "        \n",
    "        # Walltime init\n",
    "        time_begin = datetime.datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Arrays\n",
    "            self.X_tr = X_tr\n",
    "            self.X_va = X_va\n",
    "            self.y_tr = y_tr\n",
    "            self.y_va = y_va\n",
    "\n",
    "            # Valid baseline accuracy\n",
    "            baseline_accuracy = y_va[y_va[:, 0] == 0].shape[0] / y_va.shape[0]\n",
    "            print('baseline valid accuracy: {:.5f}\\n'.format(baseline_accuracy))\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in np.arange(epochs):\n",
    "                self.epoch_func(epoch, 'train', self.X_tr, self.y_tr,)\n",
    "                self.epoch_func(epoch, 'valid', self.X_va, self.y_va,)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            None\n",
    "        \n",
    "        # Total walltime\n",
    "        walltime = (datetime.datetime.now() - time_begin).total_seconds()\n",
    "        print('========= Training is finished! =========\\nwall total: {:3d}:{:02d}'.format(int(walltime // 60), int(walltime % 60),))\n",
    "    \n",
    "    \n",
    "    def predict(\n",
    "        self,\n",
    "        X_te,\n",
    "        y_te,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of prediction with the trained model.\n",
    "        \"\"\"\n",
    "        # Single epoch\n",
    "        self.epoch_func(0, 'test', X_te, y_te,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9b1754",
   "metadata": {},
   "source": [
    "### Metrics and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f85d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_accuracy_score(\n",
    "    y,\n",
    "    y_pred,\n",
    "    threshold = 0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Accuracy score.\n",
    "    \"\"\"\n",
    "    y_pred_bin = np.where(y_pred > threshold, 1, 0)\n",
    "    \n",
    "    return accuracy_score(y, y_pred_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "438129c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class numpy_iou():\n",
    "    \"\"\"\n",
    "    Metric and loss function based on the intersection-of-union (IoU) principle.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, y_pred, y_true,):\n",
    "        \"\"\"\n",
    "        Initialization and pre-computation.\n",
    "        \n",
    "        Column order of the input arrays:\n",
    "        xmin ymin xmax ymax\n",
    "        \"\"\"\n",
    "        # Init\n",
    "        self.xmin_pred = y_pred[:, 0]\n",
    "        self.ymin_pred = y_pred[:, 1]\n",
    "        self.xmax_pred = y_pred[:, 2]\n",
    "        self.ymax_pred = y_pred[:, 3]\n",
    "        self.xmin_true = y_true[:, 0]\n",
    "        self.ymin_true = y_true[:, 1]\n",
    "        self.xmax_true = y_true[:, 2]\n",
    "        self.ymax_true = y_true[:, 3]\n",
    "        \n",
    "        self.w_true = self.xmax_true - self.xmin_true\n",
    "        self.h_true = self.ymax_true - self.ymin_true\n",
    "        self.w_pred = self.xmax_pred - self.xmin_pred\n",
    "        self.h_pred = self.ymax_pred - self.ymin_pred\n",
    "        \n",
    "        a_true = self.w_true * self.h_true\n",
    "        a_pred = self.w_pred * self.h_pred\n",
    "        \n",
    "        self.eps = 1e-10\n",
    "        \n",
    "        # Area of overlap (aoo)\n",
    "        aoo = (\n",
    "            (np.minimum(self.xmax_true, self.xmax_pred) - np.maximum(self.xmin_true, self.xmin_pred))\n",
    "            * (np.minimum(self.ymax_true, self.ymax_pred) - np.maximum(self.ymin_true, self.ymin_pred))\n",
    "        )\n",
    "        \n",
    "        # Area of overlap limitation\n",
    "        aoo_limit = np.minimum(a_true, a_pred)\n",
    "        aoo[aoo > aoo_limit] = aoo_limit[aoo > aoo_limit]\n",
    "        \n",
    "        # Area of union (aou)\n",
    "        aou = a_true + a_pred - aoo\n",
    "\n",
    "        # Intersection of union\n",
    "        self.iou = np.clip(\n",
    "            aoo / (aou + self.eps),\n",
    "            0.,\n",
    "            100.\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def mean_iou_score(self,):\n",
    "        \"\"\"\n",
    "        Mean IoU score function.\n",
    "        Returns scalar.\n",
    "        \"\"\"\n",
    "        miou = np.mean(self.iou, axis=0)\n",
    "        return miou\n",
    "    \n",
    "    \n",
    "    def mean_ciou_loss(self,):\n",
    "        \"\"\"\n",
    "        Mean Complete IoU.\n",
    "        The idea had been got from the article on \"arXiv.org\".\n",
    "        \n",
    "        Formula:\n",
    "        \n",
    "        ciou_loss = 1 - iou + diou_term + aspratio_term = \n",
    "        = 1 - iou + (centre_distance / enclosing_box_diag)^2 +\n",
    "        + v^2 / ((1 - iou) + v)\n",
    "        \n",
    "        \"diou_term\" - distance IoU term\n",
    "        \"aspratio_term\" - aspect ratio term\n",
    "        \n",
    "        Computation of these terms is implemented in the final step\n",
    "        to avoid an exceed operation of assignment.\n",
    "        \"\"\"\n",
    "        # distance IoU term\n",
    "        centre_distance = np.hypot(\n",
    "            ((self.xmin_pred + self.xmax_pred) / 2) - ((self.xmin_true + self.xmax_true) / 2),\n",
    "            ((self.ymin_pred + self.ymax_pred) / 2) - ((self.ymin_true + self.ymax_true) / 2),\n",
    "        )\n",
    "        \n",
    "        enclosing_box_diag = np.sqrt(\n",
    "            np.square(\n",
    "                np.maximum(self.xmax_true, self.xmax_pred) - np.minimum(self.xmin_true, self.xmin_pred)\n",
    "            )\n",
    "            + np.square(\n",
    "                np.maximum(self.ymax_true, self.ymax_pred) - np.minimum(self.ymin_true, self.ymin_pred)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # aspect ratio term\n",
    "        # 4/(pi^2) ~ 0.40528\n",
    "        v = 0.40528 * np.square(\n",
    "            (\n",
    "                np.arctan(self.w_true / (self.h_true + self.eps))\n",
    "                - np.arctan(self.w_pred / (self.h_pred + self.eps))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # mean ciou loss\n",
    "        ciou = (\n",
    "            1.0\n",
    "            - self.iou \n",
    "            + np.clip(  # diou_term\n",
    "                np.square(centre_distance / (enclosing_box_diag + self.eps)),\n",
    "                -100.,\n",
    "                100.,\n",
    "            )\n",
    "            + np.clip(  # aspratio_term\n",
    "                np.square(v) / ((1 - self.iou) + v + self.eps),\n",
    "                -100.,\n",
    "                100.,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return np.mean(ciou, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c827b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class numpy_BCE_MCIOU_Loss():\n",
    "    \"\"\"\n",
    "    Custom loss function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, class_weights=(1.0, 1.0)): #, reg=1.0,):\n",
    "        \"\"\"\n",
    "        Initialization.\n",
    "        \"\"\"\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "        \n",
    "    def forward(self, y_pred, y_true,):\n",
    "        \"\"\"\n",
    "        Computing the loss.\n",
    "        \"\"\"\n",
    "        # Class weights\n",
    "        # weights = np.full_like(y_true[:, 0], 0.5, dtype=np.float)\n",
    "        # weights[y_true[:, 0] == 0] = class_weights[0]\n",
    "        # weights[y_true[:, 0] == 1] = class_weights[1]\n",
    "        \n",
    "        # Dummy for the class weights\n",
    "        weights = 1.\n",
    "        \n",
    "        # BCE loss\n",
    "        bce = -1. * np.mean(\n",
    "            weights * (\n",
    "                y_true[:, 0] * np.clip(np.log(y_pred[:, 0]), -100., 100.)\n",
    "                + (1 - y_true[:, 0]) * np.clip(np.log(1 - y_pred[:, 0]), -100., 100.)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # mCIoU loss\n",
    "        iou = numpy_iou(y_pred[:, 1:], y_true[:, 1:])\n",
    "        mciou = iou.mean_ciou_loss()\n",
    "        \n",
    "        # BCE_mCIoU loss\n",
    "        bce_mciou = (bce ** 2 + mciou ** 2) ** 0.5\n",
    "        \n",
    "        return bce_mciou, bce, mciou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d106f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weights_func(arr, return_dict=False):\n",
    "    \"\"\"\n",
    "    Computes weights of each class of the array.\n",
    "    Number of classes is the number of unique values.\n",
    "    \"\"\"\n",
    "    classes = np.unique(arr)\n",
    "    weights = np.zeros(classes.shape[0], dtype='float64')\n",
    "    for i in np.arange(classes.shape[0]):\n",
    "        weights[i] = arr[arr == classes[i]].shape[0] / arr.shape[0]\n",
    "    \n",
    "    if return_dict:\n",
    "        weights_dict = {}\n",
    "        for i in np.arange(classes.shape[0]):\n",
    "            weights_dict[classes[i]] = weights[i]\n",
    "        return weights_dict\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78360364",
   "metadata": {},
   "source": [
    "## Applying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba507b",
   "metadata": {},
   "source": [
    "### Checking up the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f4b63cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.69373109, 0.30626891])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.69375693, 0.30624307])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.69372694, 0.30627306])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.69287469, 0.30712531])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "entire dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14213, 1, 256, 256)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14213, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13535, 1, 256, 256)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(13535, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(271, 1, 256, 256)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(271, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(407, 1, 256, 256)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(407, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('class weights:')\n",
    "disp(class_weights_func(images.meta_ready[:, 0]))\n",
    "disp(class_weights_func(images.meta_ready[images.index_tr, 0]))\n",
    "disp(class_weights_func(images.meta_ready[images.index_va, 0]))\n",
    "disp(class_weights_func(images.meta_ready[images.index_te, 0]))\n",
    "print('\\nentire dataset:')\n",
    "disp(images.imgs.shape)\n",
    "disp(images.meta_augment.shape)\n",
    "print('\\ntrain sample:')\n",
    "disp(images.imgs[images.index_tr].shape)\n",
    "disp(images.meta_ready[images.index_tr].shape)\n",
    "print('\\nvalidation sample:')\n",
    "disp(images.imgs[images.index_va].shape)\n",
    "disp(images.meta_ready[images.index_va].shape)\n",
    "print('\\ntest sample:')\n",
    "disp(images.imgs[images.index_te].shape)\n",
    "disp(images.meta_ready[images.index_te].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca854932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.5546875 , 0.28515625, 0.70703125, 0.4296875 ],\n",
       "       [1.        , 0.26953125, 0.2109375 , 0.703125  , 0.58203125],\n",
       "       [1.        , 0.40625   , 0.140625  , 0.77734375, 0.53515625]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp(images.meta_ready[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3121dc",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94b407e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weights_func(images.meta_ready[images.index_tr, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e47da454",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "trainer = numpy_Trainer(\n",
    "    numpy_Net(batch_size),\n",
    "    numpy_BCE_MCIOU_Loss(class_weights=class_weights)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cf0d2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528d908",
   "metadata": {},
   "source": [
    "The net architecture is fitted for the entire dataset (about 14k entries), so the strong overfitting takes place whether we take only 50 entries of 14k ones.\n",
    "\n",
    "This is not a problem now because the goal is only showing the work of the algorithm.\n",
    "\n",
    "Meanwhile we can observe the decreasing of the BCE loss. The algorithm does work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf76749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training graph is refreshed every 1 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000] wall:   0:42,  loss: 1.666 / 1.626,  acc.: 0.320 / 0.280,  bce_loss: 0.697 / 0.694,  mciou_loss: 1.513 / 1.471,  miou: 0.000 / 0.000  [000]\n",
      "[001] wall:   0:41,  loss: 1.664 / 1.620,  acc.: 0.640 / 0.720,  bce_loss: 0.691 / 0.684,  mciou_loss: 1.513 / 1.468,  miou: 0.000 / 0.000  [001]\n",
      "[002] wall:   0:41,  loss: 1.663 / 1.616,  acc.: 0.680 / 0.720,  bce_loss: 0.683 / 0.673,  mciou_loss: 1.517 / 1.470,  miou: 0.000 / 0.000  [002]\n",
      "[003] wall:   0:42,  loss: 1.671 / 1.623,  acc.: 0.680 / 0.720,  bce_loss: 0.673 / 0.661,  mciou_loss: 1.529 / 1.482,  miou: 0.000 / 0.000  [003]\n",
      "[004] wall:   0:41,  loss: 1.691 / 1.644,  acc.: 0.680 / 0.720,  bce_loss: 0.664 / 0.650,  mciou_loss: 1.555 / 1.510,  miou: 0.000 / 0.000  [004]\n",
      "[005] wall:   0:41,  loss: 1.727 / 1.685,  acc.: 0.680 / 0.720,  bce_loss: 0.656 / 0.640,  mciou_loss: 1.598 / 1.558,  miou: 0.000 / 0.000  [005]\n",
      "[006] wall:   0:42,  loss: 1.788 / 1.751,  acc.: 0.680 / 0.720,  bce_loss: 0.649 / 0.631,  mciou_loss: 1.665 / 1.632,  miou: 0.000 / 0.000  [006]\n",
      "[007] wall:   0:42,  loss: 1.872 / 1.845,  acc.: 0.680 / 0.720,  bce_loss: 0.644 / 0.624,  mciou_loss: 1.757 / 1.735,  miou: 0.000 / 0.000  [007]\n",
      "[008] wall:   0:42,  loss: 1.984 / 1.961,  acc.: 0.680 / 0.720,  bce_loss: 0.640 / 0.618,  mciou_loss: 1.878 / 1.859,  miou: 0.000 / 0.000  [008]\n",
      "[009] wall:   0:42,  loss: 2.114 / 2.097,  acc.: 0.680 / 0.720,  bce_loss: 0.635 / 0.614,  mciou_loss: 2.016 / 2.003,  miou: 0.000 / 0.000  [009]\n",
      "========= Training is finished! =========\n",
      "wall total:   7:04\n"
     ]
    }
   ],
   "source": [
    "sample_size = 50\n",
    "\n",
    "trainer.fit(\n",
    "    X_tr = images.imgs[images.index_tr][:sample_size],\n",
    "    X_va = images.imgs[images.index_va][:sample_size],\n",
    "    y_tr = images.meta_ready[images.index_tr][:sample_size],\n",
    "    y_va = images.meta_ready[images.index_va][:sample_size],\n",
    "    batch_size = batch_size,\n",
    "    learning_rate = 1e-3,\n",
    "    epochs=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
